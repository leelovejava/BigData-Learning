spark运行模式：
local(本地模式)：常用于本地开发测试，本地还分为local单线程和local-cluster多线程：local[K]	本地以K worker 线程 (理想情况下, K设置为你机器的CPU核数).;
standalone(集群模式)：典型的Mater/slave模式，不过也能看出Master是有单点故障的； spark://HOST:PORT
on yarn(集群模式)： 运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算
on mesos(集群模式)： 运行在 mesos 资源管理器框架之上，由 mesos 负责资源管理，Spark 负责任务调度和计算
on cloud(集群模式)：比如 AWS 的 EC2，使用这个模式能很方便的访问 Amazon的 S3;Spark 支持多种分布式存储系统：HDFS 和 S3

本地连接(单节点运行spark应用,连接远程spark,hadoop)：
1.使用到hadoop的bin :设置： System.setProperty("HADOOP_HOME", "XXXXX/hadoop/bin") 或者配置变量:-DHADOOP_HOME=XXXXX/hadoop/bin
2.使用到hadoop权限不足： 
System.setProperty("HADOOP_USER_NAME", "atguigu")
或者设置：
<property>  
    　　<name>hadoop.security.authentication</name>  
    　　<value>simple</value>  
</property>  
如：
   val conf= new SparkConf().setAppName("wordcount0914").setMaster("local")
    val sc=new SparkContext(conf)

    sc.textFile("hdfs://hadoop100:8020/dept/dept.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).saveAsTextFile("hdfs://hadoop100:8020/sparkwordcount12")
    sc.stop()

   val conf= new SparkConf().setAppName("wordcount0914").setMaster("local[3]")----3个线程
    val sc=new SparkContext(conf)

远程连接(将idea当作Driver运行)：
1.conf.setjars(List("c：\\xx\\xx\\xx.jar"))
conf.setIfMissing("spark.driver.host","192.168.1.12")
其中：
以太网适配器 VMware Network Adapter VMnet8:

   连接特定的 DNS 后缀 . . . . . . . :
   本地链接 IPv6 地址. . . . . . . . : fe80::1e2:b62c:3361:4bef%23
   IPv4 地址 . . . . . . . . . . . . : 192.168.1.12
   子网掩码  . . . . . . . . . . . . : 255.255.255.0
   默认网关. . . . . . . . . . . . . : 192.168.1.2
                                       192.168.1.0



如：
val conf= new SparkConf().setAppName("wordcount0914").setMaster("spark://hadoop100:7077").setJars(List("F:\\scala-code\\wc0914\\target\\wordcount-jar-with-dependencies.jar"))
        .setIfMissing("spark.driver.host","192.168.1.12")






