Spark GraphX：主要用于分布式图的计算,适用于图数据搜索和社交圈子的应用,我要查找xxx 几号在哪里吃的饭
GraphX本质是RDD计算，以图的形式来表示。和RDD类似，把RDD转换成了图的方式,对图进行处理，计算

Spark GraphX包括:

vertices--顶点
使用：VertexRDD[VD](sc: SparkContext, deps: Seq[Dependency[_]]) extends RDD[(VertexId, VD)]  其中:VertexId--顶点id  VD--顶点属性
edges--边
EdgeRDD[ED](sc: SparkContext, deps: Seq[Dependency[_]]) extends RDD[Edge[ED]](sc, deps)  其中  ED--边

EdgeTriplet--三元组 
包括var srcAttr: VD ---源点属性
	var dstAttr: VD---目标顶点属性

主要的算法包括：基础的包括aggregateMessages，pregel，PageRank等等
aggregateMessages 是一个聚合操作,是很多算法中调用的它来进行实现的比如:mapReduceTriplets,collectNeighbors
主要是向邻边发消息，合并邻边收到的消息 包括三部分:
sendMsg: EdgeContext[VD, ED, A] => Unit,  -----发送消息(回调)
mergeMsg: (A, A) => A, -----合并消息
tripletFields: TripletFields = TripletFields.All)-----设置三元组(边，顶点)的过程
Expose all the fields (source, edge, and destination).

pregel:迭代的重新计算每个顶点的属性，直到满足某个确定的条件,计算最短距离过程
GraphX 中的pregel 和标准的pregal还有些不同,普通的只能计算相邻的顶点,GraphX还可以利用用户自定义的消息函数
pregel包括三部分:
vertexProgram：用户定义的顶点运行程序。它作用于每一个顶点，负责接收进来的信息，并计算新的顶点值。 ---支持了所有顶点的重新定义
sendMsg：发送消息
mergeMsg：合并消息

PageRank:比如百度，Google查询信息的时候，百度的竞价机制我不谈
为什么查询出来的,有的靠前，有的靠后,按照重要性来排序的,怎么样的重要性:PageRank算法:等级/重要性 假设:数量假设和质量假设
例子:类似于论文,Google 大数据三驾马车，重要性高,比如我写了一篇论文,没人引用,重要性降低
1.100个网页，99个都引用A网站,A就靠前----数量假设
2.A靠前了,A引用B网站，B相对靠前  ----质量假设


图构建：
1、对于顶点的构建：
     1、对于RDD[(VertexId, VD)]这种版本：
         val users: RDD[(VertexId, (String, String))] = sc.parallelize(Array((3L, ("rxin", "student")), (7L, ("jgonzal", "postdoc")),(5L, ("franklin", "prof")), (2L, ("istoica", "prof"))))
     2、对于VertexRDD[VD]这种版本：是上面版本的优化版本。
         val users1:VertexRDD[(String, String)] = VertexRDD[(String, String)](users)

2、对于边的构建：
     1、对于RDD[Edge[ED]]这种版本：
        val relationships: RDD[Edge[String]] = sc.parallelize(Array(Edge(3L, 7L, "collab"),    Edge(5L, 3L, "advisor"),Edge(2L, 5L, "colleague"), Edge(5L, 7L, "pi")))
     2、对于EdgeRDD[ED]这种版本：也是边的优化版本。
        val relationships1:EdgeRDD[String] = EdgeRDD.fromEdges(relationships)

3、对于Graph图的构建：
     1、通过Graph类的apply方法进行构建如下：Graph[VD: ClassTag, ED: ClassTag]
        val graph = Graph(users,relationships) 
        apply方法：
def apply[VD: ClassTag, ED: ClassTag](
    vertices: RDD[(VertexId, VD)],
    edges: RDD[Edge[ED]],
    defaultVertexAttr: VD = null.asInstanceOf[VD],
    edgeStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY,
    vertexStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY): Graph[VD, ED]
    
    2、通过Graph类提供fromEdges方法来构建，对于顶点的属性是使用提供的默认属性。

       val graph2 = Graph.fromEdges(relationships,defaultUser)

def fromEdges[VD: ClassTag, ED: ClassTag](
    edges: RDD[Edge[ED]],
    defaultValue: VD,
    edgeStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY,
    vertexStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY): Graph[VD, ED]

    3、通过Graph类提供的fromEdgeTuples方法类构建，对于顶点的属性是使用提供的默认属性，对于边的属性是相同边的数量。

      val relationships: RDD[(VertexId,VertexId)] = sc.parallelize(Array((3L, 7L),(5L, 3L),(2L, 5L), (5L, 7L)))
      val graph3 = Graph.fromEdgeTuples[(String,String)](relationships,defaultUser)

def fromEdgeTuples[VD: ClassTag](
    rawEdges: RDD[(VertexId, VertexId)],
    defaultValue: VD,
    uniqueEdges: Option[PartitionStrategy] = None,
    edgeStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY,
    vertexStorageLevel: StorageLevel = StorageLevel.MEMORY_ONLY): Graph[VD, Int]

	
//******************* Spark GraphX 图的基本信息转换  ****************
1、graph.numEdges  返回当前图的边的数量
2、graph.numVertices  返回当前图的顶点的数量
3、graph.inDegrees    返回当前图每个顶点入度的数量，返回类型为VertexRDD[Int]
4、graph.outDegrees   返回当前图每个顶点出度的数量，返回的类型为VertexRDD[Int]
5、graph.degrees      返回当前图每个顶点入度和出度的和，返回的类型为VertexRDD[Int]

//******************* Spark GraphX 图的转换操作  ****************
1、def mapVertices[VD2: ClassTag](map: (VertexId, VD) => VD2) (implicit eq: VD =:= VD2 = null): Graph[VD2, ED]
  对当前图每一个顶点应用提供的map函数来修改顶点的属性，返回一个新的图。
2、def mapEdges[ED2: ClassTag](map: Edge[ED] => ED2): Graph[VD, ED2]  对当前图每一条边应用提供的map函数来修改边的属性，返回一个新图。
3、def mapTriplets[ED2: ClassTag](map: EdgeTriplet[VD, ED] => ED2): Graph[VD, ED2]  对当前图每一个三元组应用提供的map函数来修改边的属性，返回一个新图。

//*********** Spark GraphX 图的结构操作  ***********
1、def reverse: Graph[VD, ED]  该操作反转一个图，产生一个新图，新图中的每条边的方向和原图每条边的方向相反。
2、def subgraph(epred: EdgeTriplet[VD, ED] => Boolean = (x => true), vpred: (VertexId, VD) => Boolean = ((v, d) => true)) : Graph[VD, ED]   该操作返回一个当前图的子图，通过传入epred函数来过滤边，通过传入vpred函数来过滤顶点，返回满足epred函数值为true的边和满足vpred函数值为true顶点组成子图。
3、def mask[VD2: ClassTag, ED2: ClassTag](other: Graph[VD2, ED2]): Graph[VD, ED]  mask函数用于求一张图和other这张图的交集，该交集的判别条件指的是：1、对于顶点，只对比顶点的ID，2、对于边，只对比边的srcID、dstID，如果other和当前图的交集中的边、顶点的属性不一致，那么mask产生的图默认采用当前图的属性。
4、def groupEdges(merge: (ED, ED) => ED): Graph[VD, ED]  该操作实现将当前图中的两条相同边（边的srcID和dstID相同）合并。你需要传入一个merge函数，用于合并这两边的属性返回一个新的属性。注意，合并两条边的前提是，两条边在一个分区。

//*********** Spark GraphX 顶点关联操作 ************
1、def joinVertices[U: ClassTag](table: RDD[(VertexId, U)])(mapFunc: (VertexId, VD, U) => VD): Graph[VD, ED]
该操作通过mapFunc函数将table中提供的数据更新到相同VertexId的属性里。、
2、def outerJoinVertices[U: ClassTag, VD2: ClassTag](other: RDD[(VertexId, U)])(mapFunc: (VertexId, VD, Option[U]) => VD2)(implicit eq: VD =:= VD2 = null): Graph[VD2, ED]
该操作和joinVertices提供了相同的功能，但是，如果table中不存在相对应的顶点（也就是不存VertexId），这个时候U默认是None。

//*********** Spark GraphX 聚合操作 *************
1、def collectNeighbors(edgeDirection: EdgeDirection): VertexRDD[Array[(VertexId, VD)]]   该操作返回EdgeDirection定义的方向中相邻顶点的ID和属性的集合。
2、def collectNeighborIds(edgeDirection: EdgeDirection): VertexRDD[Array[VertexId]]   改操作返回EdgeDirection定义的方向中相邻顶点的ID的集合。
3、def aggregateMessages[A: ClassTag](sendMsg: EdgeContext[VD, ED, A] => Unit,mergeMsg: (A, A) => A,tripletFields: TripletFields = TripletFields.All): VertexRDD[A]
该函数用于聚合发送到顶点的信息，A是发送的信息的类型，sendMsg是每一条边都会自动触发，到底有没有消息能够发送到顶点，使用EdgeContext里面的sendToSrc和sendToDst来实现。  mergeMsg是每一个顶点都会在接受到所有消息之后调用，主要用于所有接收到的消息的聚合。 然后整个函数返回VertexRDD[A],消息的顶点集合。














 